#!/usr/bin/env python3
"""
üëÅÔ∏è EXECUTION MONITOR - –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π N8N

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π workflow'–æ–≤ —á–µ—Ä–µ–∑:
- Polling –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
- Webhook listener –¥–ª—è push-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
- Anomaly detection –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π
- Event aggregation –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2025-10-02
–í–µ—Ä—Å–∏—è: 1.0
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, field
from enum import Enum
import statistics
from collections import defaultdict, deque

from connector import N8NConnector, ExecutionInfo

logger = logging.getLogger(__name__)

class EventType(Enum):
    """–¢–∏–ø—ã —Å–æ–±—ã—Ç–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    EXECUTION_STARTED = "execution_started"
    EXECUTION_COMPLETED = "execution_completed"
    EXECUTION_FAILED = "execution_failed"
    EXECUTION_TIMEOUT = "execution_timeout"
    NODE_ERROR = "node_error"
    WORKFLOW_ACTIVATED = "workflow_activated"
    WORKFLOW_DEACTIVATED = "workflow_deactivated"
    SYSTEM_ANOMALY = "system_anomaly"

class Severity(Enum):
    """–£—Ä–æ–≤–Ω–∏ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏–π"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class ExecutionEvent:
    """–°–æ–±—ã—Ç–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
    id: str
    event_type: EventType
    severity: Severity
    workflow_id: str
    execution_id: Optional[str]
    timestamp: datetime
    error_type: Optional[str] = None
    error_message: Optional[str] = None
    node_name: Optional[str] = None
    duration: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def has_errors(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–æ–±—ã—Ç–∏–µ –æ—à–∏–±–∫–∏"""
        return self.event_type in [
            EventType.EXECUTION_FAILED,
            EventType.NODE_ERROR,
            EventType.EXECUTION_TIMEOUT
        ]

@dataclass
class MonitoringStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    total_executions: int = 0
    successful_executions: int = 0
    failed_executions: int = 0
    average_execution_time: float = 0.0
    error_rate: float = 0.0
    last_updated: datetime = field(default_factory=datetime.now)
    
    def update_success_rate(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏"""
        if self.total_executions > 0:
            self.error_rate = self.failed_executions / self.total_executions
        else:
            self.error_rate = 0.0

@dataclass
class AnomalyAlert:
    """–ê–ª–µ—Ä—Ç –æ–± –∞–Ω–æ–º–∞–ª–∏–∏"""
    id: str
    anomaly_type: str
    description: str
    severity: Severity
    detected_at: datetime
    workflow_id: Optional[str] = None
    threshold_value: Optional[float] = None
    actual_value: Optional[float] = None

class ExecutionMonitor:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π N8N
    
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è workflow'–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –≤—ã—è–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã:
    - Polling –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    - Event aggregation –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    - Anomaly detection –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π
    - Performance tracking –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    """
    
    def __init__(self, connector: N8NConnector, poll_interval: int = 10):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∞"""
        self.connector = connector
        self.poll_interval = poll_interval
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.is_running = False
        self.last_poll_time = datetime.now()
        
        # –°–æ–±—ã—Ç–∏—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recent_events: deque = deque(maxlen=1000)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å–æ–±—ã—Ç–∏–π
        self.stats = MonitoringStats()
        
        # –ö—ç—à –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
        self.known_executions: Set[str] = set()
        self.execution_states: Dict[str, str] = {}  # execution_id -> status
        
        # Anomaly detection
        self.execution_times: deque = deque(maxlen=100)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –≤—Ä–µ–º–µ–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self.error_counts: Dict[str, int] = defaultdict(int)  # –°—á–µ—Ç—á–∏–∫–∏ –æ—à–∏–±–æ–∫ –ø–æ —Ç–∏–ø–∞–º
        self.anomaly_thresholds = {
            "execution_time_multiplier": 3.0,  # –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ 3 —Ä–∞–∑–∞
            "error_rate_threshold": 0.1,       # 10% –æ—à–∏–±–æ–∫
            "consecutive_failures": 5           # 5 –ø–æ–¥—Ä—è–¥ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π
        }
        
        # Webhook server (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.webhook_server = None
        self.webhook_port = 8080
        
        logger.info("üëÅÔ∏è Execution Monitor initialized")
    
    async def start(self, enable_webhook: bool = False):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        if self.is_running:
            logger.warning("‚ö†Ô∏è Monitor is already running")
            return
        
        self.is_running = True
        logger.info("üöÄ Starting execution monitoring...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º polling –≤ —Ñ–æ–Ω–µ
        polling_task = asyncio.create_task(self._polling_loop())
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º webhook server –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        webhook_task = None
        if enable_webhook:
            webhook_task = asyncio.create_task(self._start_webhook_server())
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º anomaly detection
        anomaly_task = asyncio.create_task(self._anomaly_detection_loop())
        
        try:
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
            tasks = [polling_task, anomaly_task]
            if webhook_task:
                tasks.append(webhook_task)
            
            await asyncio.gather(*tasks)
            
        except Exception as e:
            logger.error(f"‚ùå Monitor error: {e}")
        finally:
            self.is_running = False
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        logger.info("üõë Stopping execution monitoring...")
        self.is_running = False
        
        if self.webhook_server:
            await self.webhook_server.cleanup()
    
    async def _polling_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª polling'–∞"""
        logger.info("üîÑ Starting polling loop...")
        
        while self.is_running:
            try:
                await self._poll_executions()
                await asyncio.sleep(self.poll_interval)
                
            except Exception as e:
                logger.error(f"‚ùå Polling error: {e}")
                await asyncio.sleep(self.poll_interval)
    
    async def _poll_executions(self):
        """–û–ø—Ä–∞—à–∏–≤–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            executions = await self.connector.get_recent_executions(limit=100)
            
            for execution in executions:
                await self._process_execution(execution)
            
            self.last_poll_time = datetime.now()
            
        except Exception as e:
            logger.error(f"‚ùå Failed to poll executions: {e}")
    
    async def _process_execution(self, execution: ExecutionInfo):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ"""
        execution_id = execution.id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–æ–≤–æ–µ –ª–∏ —ç—Ç–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        if execution_id not in self.known_executions:
            # –ù–æ–≤–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            self.known_executions.add(execution_id)
            self.execution_states[execution_id] = execution.status
            
            # –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            event = ExecutionEvent(
                id=f"start_{execution_id}",
                event_type=EventType.EXECUTION_STARTED,
                severity=Severity.INFO,
                workflow_id=execution.workflow_id,
                execution_id=execution_id,
                timestamp=execution.started_at or datetime.now()
            )
            
            await self._add_event(event)
            self.stats.total_executions += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        old_status = self.execution_states.get(execution_id)
        if old_status != execution.status:
            self.execution_states[execution_id] = execution.status
            
            if execution.finished:
                await self._handle_execution_completion(execution)
    
    async def _handle_execution_completion(self, execution: ExecutionInfo):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        execution_id = execution.id
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è
        if execution.status == "success":
            event_type = EventType.EXECUTION_COMPLETED
            severity = Severity.INFO
            self.stats.successful_executions += 1
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è anomaly detection
            if execution.execution_time:
                self.execution_times.append(execution.execution_time)
        
        else:
            event_type = EventType.EXECUTION_FAILED
            severity = Severity.ERROR
            self.stats.failed_executions += 1
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
            self.error_counts[execution.status] += 1
        
        # –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        event = ExecutionEvent(
            id=f"complete_{execution_id}",
            event_type=event_type,
            severity=severity,
            workflow_id=execution.workflow_id,
            execution_id=execution_id,
            timestamp=execution.stopped_at or datetime.now(),
            duration=execution.execution_time
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if execution.status != "success":
            errors = await self.connector.get_execution_errors(execution_id)
            if errors:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –æ—à–∏–±–∫—É –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
                first_error = errors[0]
                event.error_type = first_error.get("error", {}).get("type", "unknown")
                event.error_message = first_error.get("error", {}).get("message", "Unknown error")
                event.node_name = first_error.get("node")
                
                # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –æ—à–∏–±–∫–∏ –Ω–æ–¥—ã
                for error in errors:
                    node_event = ExecutionEvent(
                        id=f"node_error_{execution_id}_{error['node']}",
                        event_type=EventType.NODE_ERROR,
                        severity=Severity.ERROR,
                        workflow_id=execution.workflow_id,
                        execution_id=execution_id,
                        timestamp=datetime.now(),
                        error_type=error.get("error", {}).get("type", "unknown"),
                        error_message=error.get("error", {}).get("message", "Unknown error"),
                        node_name=error.get("node")
                    )
                    await self._add_event(node_event)
        
        await self._add_event(event)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._update_stats()
    
    async def _add_event(self, event: ExecutionEvent):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –æ—á–µ—Ä–µ–¥—å"""
        self.recent_events.append(event)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        if event.severity in [Severity.ERROR, Severity.CRITICAL]:
            logger.warning(f"‚ö†Ô∏è {event.event_type.value}: {event.error_message or 'No details'}")
        elif event.event_type == EventType.EXECUTION_COMPLETED:
            logger.debug(f"‚úÖ Execution completed: {event.execution_id}")
    
    def _update_stats(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫
        self.stats.update_success_rate()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if self.execution_times:
            self.stats.average_execution_time = statistics.mean(self.execution_times)
        
        self.stats.last_updated = datetime.now()
    
    async def _anomaly_detection_loop(self):
        """–¶–∏–∫–ª –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""
        logger.info("üîç Starting anomaly detection...")
        
        while self.is_running:
            try:
                await self._detect_anomalies()
                await asyncio.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                
            except Exception as e:
                logger.error(f"‚ùå Anomaly detection error: {e}")
                await asyncio.sleep(60)
    
    async def _detect_anomalies(self):
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∞–Ω–æ–º–∞–ª–∏–∏ –≤ —Å–∏—Å—Ç–µ–º–µ"""
        anomalies = []
        
        # 1. –ê–Ω–æ–º–∞–ª–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if len(self.execution_times) >= 10:
            avg_time = statistics.mean(self.execution_times)
            recent_times = list(self.execution_times)[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π
            
            for exec_time in recent_times:
                if exec_time > avg_time * self.anomaly_thresholds["execution_time_multiplier"]:
                    anomaly = AnomalyAlert(
                        id=f"slow_execution_{int(time.time())}",
                        anomaly_type="slow_execution",
                        description=f"Execution time {exec_time:.1f}s exceeds average {avg_time:.1f}s by {self.anomaly_thresholds['execution_time_multiplier']}x",
                        severity=Severity.WARNING,
                        detected_at=datetime.now(),
                        threshold_value=avg_time * self.anomaly_thresholds["execution_time_multiplier"],
                        actual_value=exec_time
                    )
                    anomalies.append(anomaly)
        
        # 2. –ê–Ω–æ–º–∞–ª–∏–∏ —á–∞—Å—Ç–æ—Ç—ã –æ—à–∏–±–æ–∫
        if self.stats.total_executions >= 10:
            if self.stats.error_rate > self.anomaly_thresholds["error_rate_threshold"]:
                anomaly = AnomalyAlert(
                    id=f"high_error_rate_{int(time.time())}",
                    anomaly_type="high_error_rate",
                    description=f"Error rate {self.stats.error_rate:.1%} exceeds threshold {self.anomaly_thresholds['error_rate_threshold']:.1%}",
                    severity=Severity.ERROR,
                    detected_at=datetime.now(),
                    threshold_value=self.anomaly_thresholds["error_rate_threshold"],
                    actual_value=self.stats.error_rate
                )
                anomalies.append(anomaly)
        
        # 3. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–µ—É–¥–∞—á–∏
        recent_events = list(self.recent_events)[-self.anomaly_thresholds["consecutive_failures"]:]
        if len(recent_events) == self.anomaly_thresholds["consecutive_failures"]:
            if all(event.event_type == EventType.EXECUTION_FAILED for event in recent_events):
                anomaly = AnomalyAlert(
                    id=f"consecutive_failures_{int(time.time())}",
                    anomaly_type="consecutive_failures",
                    description=f"{self.anomaly_thresholds['consecutive_failures']} consecutive execution failures detected",
                    severity=Severity.CRITICAL,
                    detected_at=datetime.now(),
                    threshold_value=self.anomaly_thresholds["consecutive_failures"],
                    actual_value=self.anomaly_thresholds["consecutive_failures"]
                )
                anomalies.append(anomaly)
        
        # –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π
        for anomaly in anomalies:
            event = ExecutionEvent(
                id=anomaly.id,
                event_type=EventType.SYSTEM_ANOMALY,
                severity=anomaly.severity,
                workflow_id="system",
                execution_id=None,
                timestamp=anomaly.detected_at,
                error_type=anomaly.anomaly_type,
                error_message=anomaly.description,
                metadata={"anomaly": anomaly}
            )
            await self._add_event(event)
            
            logger.warning(f"üö® Anomaly detected: {anomaly.description}")
    
    async def _start_webhook_server(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç webhook server –¥–ª—è push-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""
        try:
            from aiohttp import web
            
            app = web.Application()
            app.router.add_post('/webhook/execution', self._handle_webhook)
            app.router.add_get('/webhook/health', self._webhook_health)
            
            runner = web.AppRunner(app)
            await runner.setup()
            
            site = web.TCPSite(runner, '0.0.0.0', self.webhook_port)
            await site.start()
            
            self.webhook_server = runner
            logger.info(f"üåê Webhook server started on port {self.webhook_port}")
            
            # –î–µ—Ä–∂–∏–º —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–Ω—ã–º
            while self.is_running:
                await asyncio.sleep(1)
                
        except Exception as e:
            logger.error(f"‚ùå Webhook server error: {e}")
    
    async def _handle_webhook(self, request):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç webhook —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è"""
        try:
            data = await request.json()
            
            # –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –∏–∑ webhook –¥–∞–Ω–Ω—ã—Ö
            event = ExecutionEvent(
                id=f"webhook_{data.get('executionId', 'unknown')}_{int(time.time())}",
                event_type=EventType(data.get('eventType', 'execution_completed')),
                severity=Severity(data.get('severity', 'info')),
                workflow_id=data.get('workflowId', 'unknown'),
                execution_id=data.get('executionId'),
                timestamp=datetime.now(),
                error_type=data.get('errorType'),
                error_message=data.get('errorMessage'),
                node_name=data.get('nodeName'),
                duration=data.get('duration')
            )
            
            await self._add_event(event)
            
            return web.json_response({"status": "ok"})
            
        except Exception as e:
            logger.error(f"‚ùå Webhook handling error: {e}")
            return web.json_response({"error": str(e)}, status=400)
    
    async def _webhook_health(self, request):
        """Health check –¥–ª—è webhook —Å–µ—Ä–≤–µ—Ä–∞"""
        return web.json_response({
            "status": "healthy",
            "uptime": str(datetime.now() - self.last_poll_time),
            "events_processed": len(self.recent_events)
        })
    
    async def get_recent_events(self, limit: int = 50, event_types: List[EventType] = None) -> List[ExecutionEvent]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è"""
        events = list(self.recent_events)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
        if event_types:
            events = [e for e in events if e.event_type in event_types]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–µ)
        events.sort(key=lambda x: x.timestamp, reverse=True)
        
        return events[:limit]
    
    async def get_events_by_workflow(self, workflow_id: str, limit: int = 50) -> List[ExecutionEvent]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ workflow"""
        events = [e for e in self.recent_events if e.workflow_id == workflow_id]
        events.sort(key=lambda x: x.timestamp, reverse=True)
        return events[:limit]
    
    async def get_error_events(self, limit: int = 50) -> List[ExecutionEvent]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è —Å –æ—à–∏–±–∫–∞–º–∏"""
        error_types = [EventType.EXECUTION_FAILED, EventType.NODE_ERROR, EventType.EXECUTION_TIMEOUT]
        return await self.get_recent_events(limit, error_types)
    
    def get_stats(self) -> MonitoringStats:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        return self.stats
    
    def get_anomaly_thresholds(self) -> Dict[str, float]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ä–æ–≥–∏ –¥–ª—è anomaly detection"""
        return self.anomaly_thresholds.copy()
    
    def update_anomaly_thresholds(self, thresholds: Dict[str, float]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ—Ä–æ–≥–∏ –¥–ª—è anomaly detection"""
        self.anomaly_thresholds.update(thresholds)
        logger.info(f"üîß Updated anomaly thresholds: {thresholds}")
    
    async def force_poll(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç polling"""
        logger.info("üîÑ Force polling executions...")
        await self._poll_executions()
    
    def clear_events(self):
        """–û—á–∏—â–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
        self.recent_events.clear()
        logger.info("üóëÔ∏è Events cleared")

# –£—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

async def create_test_monitor() -> ExecutionMonitor:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    from connector import N8NConnector
    
    connector = N8NConnector()
    await connector.connect()
    
    monitor = ExecutionMonitor(connector, poll_interval=5)
    return monitor

async def monitor_workflow_execution(workflow_id: str, timeout: int = 300) -> List[ExecutionEvent]:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ workflow"""
    monitor = await create_test_monitor()
    
    start_time = time.time()
    events = []
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ñ–æ–Ω–µ
        monitor_task = asyncio.create_task(monitor.start())
        
        # –ñ–¥–µ–º —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ timeout
        while time.time() - start_time < timeout:
            workflow_events = await monitor.get_events_by_workflow(workflow_id)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            for event in workflow_events:
                if event.event_type in [EventType.EXECUTION_COMPLETED, EventType.EXECUTION_FAILED]:
                    events = workflow_events
                    break
            
            if events:
                break
            
            await asyncio.sleep(1)
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        await monitor.stop()
        monitor_task.cancel()
        
        return events
        
    except Exception as e:
        logger.error(f"‚ùå Monitoring error: {e}")
        return []
